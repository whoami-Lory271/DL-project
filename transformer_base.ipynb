{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/DL-project/blob/main/transformer_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install library import "
      ],
      "metadata": {
        "id": "EYE_g4aS0itt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning\n",
        "!import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "q7IXEB390pTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.normalization import LayerNorm\n",
        "\n",
        "from numpy import array\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.normalization import LayerNorm\n",
        "import pickle\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv"
      ],
      "metadata": {
        "id": "6r_zVhYLKhqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pXssHefj0dTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "j2OkY9ii2qjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/Deep learning\" #change if needed"
      ],
      "metadata": {
        "id": "DE4BW2JmUeSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take all the txt files\n",
        "dataset_path=\"/content/drive/MyDrive/Deep learning/train_data\"\n",
        "ft_texts_path=[str(path) for path in Path(dataset_path).glob(\"*.txt\")]\n",
        "print(ft_texts_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn80Hyh870Fq",
        "outputId": "18b976c3-12ba-40bc-9059-c1e3ba186a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Deep learning/train_data/probability__swr_p_level_set_easy.txt', '/content/drive/MyDrive/Deep learning/train_data/algebra__linear_1d_easy.txt', '/content/drive/MyDrive/Deep learning/train_data/calculus__differentiate_easy.txt', '/content/drive/MyDrive/Deep learning/train_data/calculus__differentiate_hard.txt', '/content/drive/MyDrive/Deep learning/train_data/probability__swr_p_level_set_hard.txt', '/content/drive/MyDrive/Deep learning/train_data/algebra__linear_1d_hard.txt', '/content/drive/MyDrive/Deep learning/train_data/probability__swr_p_level_set_medium.txt', '/content/drive/MyDrive/Deep learning/train_data/algebra__linear_1d_medium.txt', '/content/drive/MyDrive/Deep learning/train_data/calculus__differentiate_medium.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vocabulary_from_directory(sentences_path):\n",
        "  vocabulary = {}\n",
        "  vocabulary['<sos>'] = 1\n",
        "  vocabulary['<eos>'] = 2\n",
        "  vocabulary['<pad>'] = 0\n",
        "  index = 3\n",
        "  conta = 0\n",
        "  for file in sentences_path:\n",
        "    with open(file, 'r') as file_in:\n",
        "      text = file_in.read()\n",
        "      sentences = text.split('\\n')\n",
        "      sentences_new = sentences[:-1] #remove last element because it's empty\n",
        "      print(\"num sentences\", len(sentences_new))\n",
        "      for s in sentences_new:\n",
        "        conta +=1\n",
        "        for t in s:\n",
        "         if t not in vocabulary:\n",
        "            vocabulary[t] = index\n",
        "            index += 1\n",
        "      file_in.close()\n",
        "  return vocabulary, conta"
      ],
      "metadata": {
        "id": "NenOz7Bnz1gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary, conta = create_vocabulary_from_directory(ft_texts_path)\n",
        "print(conta)"
      ],
      "metadata": {
        "id": "gw7vYDuiy5hA",
        "outputId": "c94159ab-ae90-40ca-eb8c-079f5f8bded4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "11999988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create the pickle\n",
        "outfile = open(os.path.join(save_path,\"vocabs\"), 'wb')\n",
        "pickle.dump(vocabulary, outfile)\n",
        "outfile.close()"
      ],
      "metadata": {
        "id": "hozVF8z6KqDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoding_from_sentence(vocab, sentence):\n",
        "  enc= [1]\n",
        "  for token in sentence:\n",
        "    enc.append(vocab[token])\n",
        "  enc.append(2)\n",
        "  return enc"
      ],
      "metadata": {
        "id": "yE-32CsOX3en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding(encode, vocab, max_len):\n",
        "    enc = np.array(encode)\n",
        "    encoded = np.zeros(max_len + 2)\n",
        "    for k in range(len(enc)):\n",
        "      encoded[k] = enc[k]\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "C4JVsg3-t_RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pickles(vocabulary, sentences_paths, column_names=[\"Sentence\", \"Encoding\"], path_quest=\"/content/drive/MyDrive/Deep learning/questions\", path_answ=\"/content/drive/MyDrive/Deep learning/answers\"):\n",
        "  quest = []\n",
        "  answ = []\n",
        "  out_file_quest = open(path_quest, 'wb')\n",
        "  out_file_answ = open(path_answ, 'wb')\n",
        "  for file in sentences_paths:\n",
        "    with open(file, 'r') as file_in:\n",
        "      text = file_in.read()\n",
        "      sentences = text.split('\\n')\n",
        "      sentences = sentences[:-1]\n",
        "      print(\"num sentences\", len(sentences))\n",
        "      for i, sentence in enumerate(sentences):\n",
        "          enc = encoding_from_sentence(vocabulary, sentence)\n",
        "          if i % 2 == 0: #question\n",
        "            quest.append({\"Sentence\": sentence, \"Encoding\": enc})\n",
        "          elif i % 2 == 1: #answer\n",
        "            answ.append({\"Sentence\": sentence, \"Encoding\": enc})\n",
        "  pickle.dump(quest, out_file_quest)\n",
        "  pickle.dump(answ, out_file_answ)\n",
        "  out_file_quest.close()\n",
        "  out_file_answ.close()\n",
        "  return path_quest, path_answ"
      ],
      "metadata": {
        "id": "VJbw05t8Mjdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "C8mQUo-4MPvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unpickle the vocabulary\n",
        "infile = open(os.path.join(save_path,'vocabs'),'rb')\n",
        "vocab = pickle.load(infile)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd85066-b0b7-4429-869c-2c00ace75f46",
        "id": "eJKBOht4EPHd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<sos>': 1, '<eos>': 2, '<pad>': 0, 'W': 3, 'h': 4, 'a': 5, 't': 6, ' ': 7, 'i': 8, 's': 9, 'p': 10, 'r': 11, 'o': 12, 'b': 13, 'f': 14, 'c': 15, 'k': 16, 'n': 17, 'g': 18, '1': 19, 'd': 20, 'w': 21, 'e': 22, 'l': 23, 'u': 24, 'm': 25, '?': 26, '4': 27, '/': 28, '9': 29, 'y': 30, '{': 31, ':': 32, ',': 33, '2': 34, 'z': 35, '}': 36, '5': 37, 'F': 38, '6': 39, '.': 40, '3': 41, '8': 42, 'j': 43, '0': 44, 'C': 45, 'T': 46, 'x': 47, '7': 48, 'v': 49, 'q': 50, 'G': 51, 'S': 52, '=': 53, '*': 54, '+': 55, '-': 56, 'D': 57}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_quest, path_answ = create_pickles(vocab, ft_texts_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCFq3MbYYrbv",
        "outputId": "99e1f1df-5395-4e3e-c71e-44c5fb221e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n",
            "num sentences 1333332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unpickle the qestions\n",
        "infile = open(os.path.join(save_path,\"questions\"),'rb')\n",
        "quest = pickle.load(infile)\n",
        "print(len(quest))\n",
        "\n",
        "#unpickle the answers\n",
        "infile = open(os.path.join(save_path,\"answers\"),'rb')\n",
        "answ = pickle.load(infile)\n",
        "print(len(answ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8e47VRR05pB",
        "outputId": "d70cbd3a-8a52-4614-a7c4-3819b7643e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5999994\n",
            "5999994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(answ[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BWCWe7U3sxB",
        "outputId": "2247f3a5-16cd-4fd4-e51d-66ff15e8eff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Sentence': '4/9', 'Encoding': [1, 27, 28, 29, 2]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_Dataset(Dataset):\n",
        "  def __init__(self, file_quest, file_answ, vocab , max_len_quest=160, max_len_answ=30):\n",
        "    self.file_quest = file_quest\n",
        "    self.file_answ = file_answ\n",
        "    self.vocab = vocab\n",
        "    self.max_len_quest = max_len_quest\n",
        "    self.max_len_answ = max_len_answ\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.file_quest)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    assert(idx  < len(self.file_quest)) #indices should start from 0 to len - 1 (there are 5999994 elements)\n",
        "    question = self.file_quest[idx][\"Encoding\"]\n",
        "    encoding1 = torch.from_numpy(create_padding(question, self.vocab, self.max_len_quest))\n",
        "    encoding1 = encoding1.type(torch.int)\n",
        "    #self.sample[\"Question\"] = encoding\n",
        "      \n",
        "    answer = self.file_answ[idx][\"Encoding\"]\n",
        "    encoding2 = torch.from_numpy(create_padding(answer, self.vocab, self.max_len_answ))\n",
        "    encoding2 = encoding2.type(torch.int)\n",
        "    #self.sample[\"Answer\"] = encoding\n",
        "      \n",
        "    return encoding1, encoding2 "
      ],
      "metadata": {
        "id": "bCskAS9LMNTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dataset\n",
        "dataset = Custom_Dataset(quest, answ, vocab)"
      ],
      "metadata": {
        "id": "sAQcoCkOo44i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quest = None\n",
        "answ = None"
      ],
      "metadata": {
        "id": "fTMK3NONx7ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnNW2wFCpRFu",
        "outputId": "b609819e-a34b-473a-d078-05257ec45cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([ 1,  3,  4,  5,  6,  7,  8,  9,  7, 10, 11, 12, 13,  7, 12, 14,  7, 10,\n",
            "         8, 15, 16,  8, 17, 18,  7, 19,  7, 13,  7,  5, 17, 20,  7, 19,  7, 10,\n",
            "         7, 21,  4, 22, 17,  7,  6, 21, 12,  7, 23, 22,  6,  6, 22, 11,  9,  7,\n",
            "        10,  8, 15, 16, 22, 20,  7, 21,  8,  6,  4, 12, 24,  6,  7, 11, 22, 10,\n",
            "        23,  5, 15, 22, 25, 22, 17,  6,  7, 14, 11, 12, 25,  7,  6, 10, 10, 10,\n",
            "        13, 13, 10, 13, 13, 13, 26,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       dtype=torch.int32), tensor([ 1, 27, 28, 29,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       dtype=torch.int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dataloader\n",
        "train_loader = DataLoader(dataset, 32, shuffle=True)\n",
        "print(len(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Zzt0OmDgbi",
        "outputId": "24374fb6-ff47-4f51-a932-83bf59e791d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "187500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"data\", next(iter(train_loader)))\n",
        "print(\"questions_shape \", next(iter(train_loader))[0].shape)\n",
        "\n",
        "print(\"answers_shape \", next(iter(train_loader))[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWqFcYLND4ZE",
        "outputId": "f0587f27-1896-4e4f-df48-d386261b1eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data [tensor([[ 1, 38,  8,  ...,  0,  0,  0],\n",
            "        [ 1, 38,  8,  ...,  0,  0,  0],\n",
            "        [ 1, 52, 12,  ...,  0,  0,  0],\n",
            "        ...,\n",
            "        [ 1, 52, 12,  ...,  0,  0,  0],\n",
            "        [ 1, 46, 21,  ...,  0,  0,  0],\n",
            "        [ 1, 52, 12,  ...,  0,  0,  0]], dtype=torch.int32), tensor([[ 1, 34, 54,  ...,  0,  0,  0],\n",
            "        [ 1, 56, 37,  ...,  0,  0,  0],\n",
            "        [ 1, 19, 39,  ...,  0,  0,  0],\n",
            "        ...,\n",
            "        [ 1, 34, 39,  ...,  0,  0,  0],\n",
            "        [ 1, 19, 37,  ...,  0,  0,  0],\n",
            "        [ 1, 56, 34,  ...,  0,  0,  0]], dtype=torch.int32)]\n",
            "questions_shape  torch.Size([32, 162])\n",
            "answers_shape  torch.Size([32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "Kf5YD-k_z5H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vocabulary(sentences):\n",
        "  vocabulary = {}\n",
        "  vocabulary['<sos>'] = 1\n",
        "  vocabulary['<eos>'] = 2\n",
        "  vocabulary['<pad>'] = 0\n",
        "  index = 3\n",
        "  for s in sentences:\n",
        "    tokens = s.split()\n",
        "    for t in tokens:\n",
        "      if t not in vocabulary:\n",
        "        vocabulary[t] = index\n",
        "        index += 1\n",
        "  return vocabulary"
      ],
      "metadata": {
        "id": "6SSXBIoaKEG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoding(vocabulary,sentences):\n",
        "  X = [[vocabulary[token]] for sentence in sentences for token in sentence.split()]\n",
        "  X = torch.tensor(X)\n",
        "  X = X.reshape((len(sentences),X.shape[0] // len(sentences)))\n",
        "  \n",
        "  pad = X == vocabulary['<pad>']\n",
        "  padding_mask = pad.repeat(1,1,X.shape[1]).reshape((X.shape[0],X.shape[1],X.shape[1]))\n",
        "  padding_mask[pad] = True\n",
        "\n",
        "  return X,padding_mask"
      ],
      "metadata": {
        "id": "uhBTERsqGOca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingLayer(nn.Module):\n",
        "  def __init__(self,vocabulary_size,embedding_dim):\n",
        "    super().__init__()\n",
        "    self.E = nn.Embedding(vocabulary_size,embedding_dim)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.E(x)"
      ],
      "metadata": {
        "id": "C4i4vs8nLKNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def position_embedding(batch_size,seq_length,emb_dim,pad_mask):\n",
        "  res = torch.zeros((batch_size,seq_length,emb_dim),dtype=torch.float32)\n",
        "  for pos in range(seq_length):\n",
        "    for i in range(emb_dim):\n",
        "      if i%2 == 0:\n",
        "        res[:,pos,i] = math.sin(pos/10000**(2*i/emb_dim))\n",
        "      else:\n",
        "        res[:,pos,i] = math.cos(pos/10000**(2*i/emb_dim))\n",
        "  res[pad_mask[:,0,:]] = 0\n",
        "  return res"
      ],
      "metadata": {
        "id": "B8E2HleXTgFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TPSelfAttention(nn.Module):\n",
        "  def __init__(self,dz,dk):\n",
        "    super().__init__()\n",
        "    self.dk = dk\n",
        "    self.Wq = nn.Linear(dz,dk)\n",
        "    self.Wk = nn.Linear(dz,dk)\n",
        "    self.Wv = nn.Linear(dz,dk)\n",
        "    self.Wr = nn.Linear(dz,dk)\n",
        "    self.Wo = nn.Linear(dk,dz)\n",
        "    self.softmax = nn.Softmax(dim=2)\n",
        "  \n",
        "  def forward(self,x,padding_mask,enc=None,mask=False,other_mask=None):\n",
        "    q = self.Wq(x)\n",
        "    r = self.Wr(x)\n",
        "    if enc == None:\n",
        "      k = self.Wk(x)\n",
        "      v = self.Wv(x)\n",
        "    else:\n",
        "      k = self.Wk(enc)\n",
        "      v = self.Wv(enc)\n",
        "    sc = torch.matmul(q,k.permute(0,2,1)) / math.sqrt(self.dk)\n",
        "\n",
        "    if other_mask == None:\n",
        "      sc[padding_mask] = float('-inf')\n",
        "    else:\n",
        "      qmod = q.clone()\n",
        "      kmod = k.clone()\n",
        "      qmod[padding_mask[:,0,:]] = 0\n",
        "      kmod[other_mask[:,0,:]] = 0\n",
        "      sc = torch.matmul(qmod,kmod.permute(0,2,1)) / math.sqrt(self.dk)\n",
        "      sc[sc == 0] = float('-inf')\n",
        "\n",
        "    if mask==True:\n",
        "      for i in range(sc.shape[1]):\n",
        "        sc[:,i,i+1:] = float('-inf')\n",
        "    score = torch.matmul(torch.nan_to_num(self.softmax(sc)),v)\n",
        "    return self.Wo(r * score)"
      ],
      "metadata": {
        "id": "v9OoIF1MgYIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TPMultiHeadAttention(nn.Module):\n",
        "  def __init__(self,dmodel,nhead,dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.nhead = nhead\n",
        "    self.att_layers = nn.ModuleList([TPSelfAttention(dmodel,dmodel // nhead) for i in range(nhead)])\n",
        "    self.drop = nn.Dropout(p=dropout)\n",
        "  \n",
        "  def forward(self,x,padding_mask,enc=None,mask=False,other_mask=None):\n",
        "    y = self.att_layers[0](x,padding_mask,enc=enc,mask=mask,other_mask=other_mask)\n",
        "    for i in range(1,self.nhead):\n",
        "      y += self.att_layers[i](x,padding_mask,enc=enc,mask=mask,other_mask=other_mask)\n",
        "    y = self.drop(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "wJS-HOR2mYjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FFN(nn.Module):\n",
        "  def __init__(self,dmodel,df,dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.W1 = nn.Linear(dmodel,df)\n",
        "    self.W2 = nn.Linear(df,dmodel)\n",
        "    self.drop = nn.Dropout(p=dropout)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.W1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.W2(x)\n",
        "    x = self.drop(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Q3a-LqjhyGER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,dmodel,df,nhead):\n",
        "    super().__init__()\n",
        "    self.norm = LayerNorm(dmodel)\n",
        "    self.mha = TPMultiHeadAttention(dmodel,nhead)\n",
        "    self.norm1 = LayerNorm(dmodel)\n",
        "    self.ffn = FFN(dmodel,df)\n",
        "    self.norm2 = LayerNorm(dmodel)\n",
        "  \n",
        "  def forward(self,x,padding_mask):\n",
        "    x = self.norm(x)\n",
        "    z = self.mha(x,padding_mask)\n",
        "    z = self.norm1(x+z)\n",
        "    y = self.ffn(z)\n",
        "    return self.norm2(z+y)"
      ],
      "metadata": {
        "id": "mIPuC2RAypA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,dmodel,df,nhead):\n",
        "    super().__init__()\n",
        "    self.norm = LayerNorm(dmodel)\n",
        "    self.masked_mha = TPMultiHeadAttention(dmodel,nhead)\n",
        "    self.norm1 = LayerNorm(dmodel)\n",
        "    self.enc_dec_attention = TPMultiHeadAttention(dmodel,nhead)\n",
        "    self.norm2 = LayerNorm(dmodel)\n",
        "    self.ffn = FFN(dmodel,df)\n",
        "    self.norm3 = LayerNorm(dmodel)\n",
        "  \n",
        "  def forward(self,x,enc,padding_mask,other_mask):\n",
        "    x = self.norm(x)\n",
        "    z1= self.masked_mha(x,padding_mask,mask=True)\n",
        "    z1 = self.norm1(x+z1)\n",
        "    z2= self.enc_dec_attention(z1,padding_mask,enc=enc,mask=False,other_mask=other_mask)\n",
        "    z2 = self.norm2(z1+z2)\n",
        "    y = self.ffn(z2)\n",
        "    return self.norm3(z2+y)"
      ],
      "metadata": {
        "id": "DLqzXKv6kRua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self,voc_size,dmodel,df,nhead,nlayers,dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.nlayers = nlayers\n",
        "    self.embedding = EmbeddingLayer(voc_size,dmodel)\n",
        "    self.encoders = nn.ModuleList([Encoder(dmodel,df,nhead) for i in range(nlayers)])\n",
        "    self.decoders = nn.ModuleList([Decoder(dmodel,df,nhead) for i in range(nlayers)])\n",
        "    self.drop1 = nn.Dropout(p=dropout)\n",
        "    self.drop2 = nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self,x,z,in_padding_mask,out_padding_mask,encoding=True):\n",
        "    if encoding:\n",
        "      emb = self.embedding(x)\n",
        "      t = position_embedding(x.shape[0],x.shape[1],dmodel,in_padding_mask)\n",
        "      x = emb + t\n",
        "      x = self.drop1(x)\n",
        "      for i in range(self.nlayers):\n",
        "        x = self.encoders[i](x,in_padding_mask)\n",
        "\n",
        "    emb = self.embedding(z)\n",
        "    t = position_embedding(z.shape[0],z.shape[1],dmodel,out_padding_mask)\n",
        "    z = emb + t\n",
        "    z = self.drop2(z)\n",
        "    for i in range(self.nlayers):\n",
        "      z = self.decoders[i](z,x,out_padding_mask,in_padding_mask)\n",
        "    \n",
        "    z = z @ self.embedding.E.weight.T\n",
        "\n",
        "    return x,z"
      ],
      "metadata": {
        "id": "0lB1U2Ee4UCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_sentences = [\"<sos> dai ragazzi per una volta che ci andiamo non scegliamo il posto che fa pagare poco <eos>\",\"<sos> altrimenti tanto vale andare a mensa <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\",\"<sos> importante è la compagnia <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\"]\n",
        "in_vocabulary = create_vocabulary(in_sentences)"
      ],
      "metadata": {
        "id": "qFlLPZH78meU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_sentences = [\"<sos> come on guys for once let's not choose the place that charges little <eos>\",\"<sos> otherwise we might as well go to the canteen <eos> <pad> <pad> <pad> <pad>\",\"<sos> important is company <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\"]\n",
        "out_vocabulary = create_vocabulary(out_sentences)"
      ],
      "metadata": {
        "id": "Z6oWxTJqkbRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(in_vocabulary)\n",
        "print(out_vocabulary)"
      ],
      "metadata": {
        "id": "5hT4pAqsYoOU",
        "outputId": "27e9e38d-1544-461d-f5f7-e7053690768f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<sos>': 1, '<eos>': 2, '<pad>': 0, 'dai': 3, 'ragazzi': 4, 'per': 5, 'una': 6, 'volta': 7, 'che': 8, 'ci': 9, 'andiamo': 10, 'non': 11, 'scegliamo': 12, 'il': 13, 'posto': 14, 'fa': 15, 'pagare': 16, 'poco': 17, 'altrimenti': 18, 'tanto': 19, 'vale': 20, 'andare': 21, 'a': 22, 'mensa': 23, 'importante': 24, 'è': 25, 'la': 26, 'compagnia': 27}\n",
            "{'<sos>': 1, '<eos>': 2, '<pad>': 0, 'come': 3, 'on': 4, 'guys': 5, 'for': 6, 'once': 7, \"let's\": 8, 'not': 9, 'choose': 10, 'the': 11, 'place': 12, 'that': 13, 'charges': 14, 'little': 15, 'otherwise': 16, 'we': 17, 'might': 18, 'as': 19, 'well': 20, 'go': 21, 'to': 22, 'canteen': 23, 'important': 24, 'is': 25, 'company': 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input,in_pad_mask = encoding(in_vocabulary,in_sentences)\n",
        "teacher,out_pad_mask = encoding(out_vocabulary,out_sentences)"
      ],
      "metadata": {
        "id": "TcuxIU-xLZd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dmodel = 512\n",
        "dk,dv = 64,64\n",
        "nhead = 8\n",
        "df = 2048\n",
        "nlayers = 6\n",
        "in_vocabulary_size = len(in_vocabulary.keys())\n",
        "out_vocabulary_size = len(out_vocabulary.keys())"
      ],
      "metadata": {
        "id": "K_rQ4Hrr9m9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(in_vocabulary_size)\n",
        "print(out_vocabulary_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBSzhQRbtGJl",
        "outputId": "4528ac4b-3c4b-4b91-db12-f3692186a798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tran = Transformer(in_vocabulary_size,dmodel,df,nhead,nlayers)"
      ],
      "metadata": {
        "id": "rcDDXSJ38CgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(tran.parameters(),lr=1e-04, betas=(0.9, 0.98), eps=1e-09)\n",
        "\n",
        "tran.train()\n",
        "\n",
        "for i in range(100):\n",
        "    \n",
        "  opt.zero_grad()\n",
        "  x,output = tran(input,teacher,in_pad_mask,out_pad_mask)\n",
        "  pred = output[:,:-1,:].reshape(output.shape[0]*(output.shape[1] - 1),output.shape[2])\n",
        "  target = teacher[:,1:].reshape(teacher.shape[0]*(teacher.shape[1] - 1))\n",
        "  l = loss(pred,target)\n",
        "  l.backward()\n",
        "  if i%10 == 0 or i == 99:\n",
        "    print(l)\n",
        "  #nn.utils.clip_grad_norm_(tran.parameters(), 0.1)\n",
        "  opt.step()\n",
        "  "
      ],
      "metadata": {
        "id": "7WhL-aIhw81n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "6bb3d813-3ef0-4e4b-d495-fef23a4f12f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(89.6699, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0374, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-209-9b858d919763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtran\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_pad_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_pad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-193-c519bbd491b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, z, in_padding_mask, out_padding_mask, encoding)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-191-073417f35dfd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, padding_mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-190-d0eb5e3c43f1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.argmax(-1)[:,:-1]"
      ],
      "metadata": {
        "id": "xgf5xod8CrmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "424aa615-c264-4658-b8bc-dc5c6cbc87ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
              "        [ 1, 16, 17, 18, 19, 20, 21, 22, 11, 23,  2,  0,  0,  0],\n",
              "        [ 1, 24, 25, 26,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher[:,1:]"
      ],
      "metadata": {
        "id": "LIegSrEkCu8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497f91d9-49cc-4bb5-a5a1-4b633330502e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,  2],\n",
              "        [16, 17, 18, 19, 20, 21, 22, 11, 23,  2,  0,  0,  0,  0],\n",
              "        [24, 25, 26,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_test = [\"<sos> ragazzi andiamo a mensa <eos> <pad> <pad>\",\"<sos> il posto fa pagare la compagnia <eos>\"]\n",
        "out_test = [\"<sos> guys let's go to the canteen <eos>\",\"<sos> the place charges the company <eos> <pad>\"]"
      ],
      "metadata": {
        "id": "np1c4sE_MVXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_test,in_test_pad_mask = encoding(in_vocabulary,in_test)\n",
        "target_test,out_test_pad_mask = encoding(out_vocabulary,out_test)"
      ],
      "metadata": {
        "id": "mfuAcZAsMXUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = input_test\n",
        "enc = True\n",
        "trg = target_test.clone()\n",
        "for i in range(1,target_test.shape[1]):\n",
        "  x,output = tran(x,trg[:,:i],in_test_pad_mask,out_test_pad_mask[:,:i,:i],encoding = enc)\n",
        "  trg[:,i] = output.argmax(-1)[:,-1]\n",
        "  enc = False"
      ],
      "metadata": {
        "id": "pVhluSNDMXtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.argmax(-1)"
      ],
      "metadata": {
        "id": "nswprQEINdAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04faa3f-8cbf-4caf-91a0-1a2478cc93cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1, 18,  1,  1, 18,  1,  1],\n",
              "        [ 1,  1,  1,  1,  1,  1,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_test[:,1:]"
      ],
      "metadata": {
        "id": "k4f7--1lNfZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f7c7a3-219c-4489-ea34-60ef9e35a31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5,  8, 21, 22, 11, 23,  2],\n",
              "        [11, 12, 14, 11, 26,  2,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    }
  ]
}