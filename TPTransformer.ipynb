{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d9c608b1d90413887825d871296cdd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4c4ffed5ac94647957b460ad4eb08d8",
              "IPY_MODEL_790be6408edb4b9c9ffea8d11c66d1e5",
              "IPY_MODEL_ed066fbfebd94bfeb764fb6ce2bb78bb"
            ],
            "layout": "IPY_MODEL_3d5e01f3a2ad4c79828df95b67aebd43"
          }
        },
        "a4c4ffed5ac94647957b460ad4eb08d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6779fcbea64b47fd83671cb969a15fed",
            "placeholder": "​",
            "style": "IPY_MODEL_3b058c3412694c23b94c9de351593c34",
            "value": "Epoch 2: 100%"
          }
        },
        "790be6408edb4b9c9ffea8d11c66d1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7de1a75bab3d419c91544d2b8a23d2cc",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80b58710ce254035bfa611290d9bfe79",
            "value": 4
          }
        },
        "ed066fbfebd94bfeb764fb6ce2bb78bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf9bd7ad2e5f4051ab7e8cf4ab59c879",
            "placeholder": "​",
            "style": "IPY_MODEL_910e60784f7a4ef1a396c3fc8f7d2e7c",
            "value": " 4/4 [00:27&lt;00:00,  6.99s/it, loss=8.8, v_num=2, train_loss_step=6.680, train_loss_epoch=6.490]"
          }
        },
        "3d5e01f3a2ad4c79828df95b67aebd43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6779fcbea64b47fd83671cb969a15fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b058c3412694c23b94c9de351593c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7de1a75bab3d419c91544d2b8a23d2cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b58710ce254035bfa611290d9bfe79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf9bd7ad2e5f4051ab7e8cf4ab59c879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "910e60784f7a4ef1a396c3fc8f7d2e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "135a2c3cfd2e433f9db5cc9fe0775cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4f1ebe85e5d438fbe8a057b11542b7d",
              "IPY_MODEL_0f6e1773e3384e85a232ed0b2acbeeae",
              "IPY_MODEL_b69c69f55ed2412b986c38a5435fa3a2"
            ],
            "layout": "IPY_MODEL_3f0b86d34b6448afaaaeb1a66a131e22"
          }
        },
        "a4f1ebe85e5d438fbe8a057b11542b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad0447576df8476f961aaa2101fb70b5",
            "placeholder": "​",
            "style": "IPY_MODEL_b996c36a16d7461996eebeee32838f25",
            "value": "Testing DataLoader 0: 100%"
          }
        },
        "0f6e1773e3384e85a232ed0b2acbeeae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd5289872ded4076858e775b83bf054d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbbe334888d24fcbad00a1fd59e9a88f",
            "value": 2
          }
        },
        "b69c69f55ed2412b986c38a5435fa3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76fdd681bb95440b968d097435e388c9",
            "placeholder": "​",
            "style": "IPY_MODEL_d87aefefc0e64fad914e8f26673e9c3f",
            "value": " 2/2 [00:35&lt;00:00, 17.78s/it]"
          }
        },
        "3f0b86d34b6448afaaaeb1a66a131e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "ad0447576df8476f961aaa2101fb70b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b996c36a16d7461996eebeee32838f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd5289872ded4076858e775b83bf054d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbe334888d24fcbad00a1fd59e9a88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76fdd681bb95440b968d097435e388c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d87aefefc0e64fad914e8f26673e9c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoami-Lory271/DL-project/blob/main/TPTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install library import "
      ],
      "metadata": {
        "id": "EYE_g4aS0itt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning --quiet\n",
        "!pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "q7IXEB390pTj",
        "outputId": "54764f00-6107-4510-d6f4-ca957734715c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.normalization import LayerNorm\n",
        "\n",
        "from numpy import array\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.normalization import LayerNorm\n",
        "import pickle\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import torchmetrics\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar"
      ],
      "metadata": {
        "id": "6r_zVhYLKhqs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "egcxUIj5C4dr",
        "outputId": "6e2bdaa4-3a5e-4ff0-9c16-6eca84048f67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Function"
      ],
      "metadata": {
        "id": "ojG0bbT6C-JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_padding_mask(X):\n",
        "  pad = X == 0\n",
        "  padding_mask = pad.repeat(1,1,X.shape[1]).reshape((X.shape[0],X.shape[1],X.shape[1]))\n",
        "  padding_mask[pad] = True\n",
        "  return padding_mask"
      ],
      "metadata": {
        "id": "oZ4yDtvtGMSC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding(encode, vocab, max_len):\n",
        "    enc = np.array(encode)\n",
        "    encoded = np.zeros(max_len + 2)\n",
        "    for k in range(len(enc)):\n",
        "      encoded[k] = enc[k]\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "C4JVsg3-t_RN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "j2OkY9ii2qjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/Deep learning\" #change if needed"
      ],
      "metadata": {
        "id": "DE4BW2JmUeSB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path for easy train data:"
      ],
      "metadata": {
        "id": "05HMjuQ8AkRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#take all the txt files\n",
        "easy_path = os.path.join(save_path,\"easy_pickle\")\n",
        "easy_texts_path=[str(path) for path in Path(easy_path).glob(\"*.txt\")]\n",
        "print(easy_texts_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pVI-CFneMDR",
        "outputId": "b9fafbaa-9776-48ef-df92-135fb164939d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Deep learning/easy_pickle/algebra__linear_1d_easy.txt', '/content/drive/MyDrive/Deep learning/easy_pickle/calculus__differentiate_easy.txt', '/content/drive/MyDrive/Deep learning/easy_pickle/probability__swr_p_level_set_easy.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path for medium train data:"
      ],
      "metadata": {
        "id": "gq78jqGTAnmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medium_path= os.path.join(save_path,\"medium_pickle\")\n",
        "medium_texts_path=[str(path) for path in Path(medium_path).glob(\"*.txt\")]\n",
        "print(medium_texts_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lVIhd7-eMzJ",
        "outputId": "506120a9-468c-46aa-fe77-8219d174e73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Deep learning/medium_pickle/algebra__linear_1d_medium.txt', '/content/drive/MyDrive/Deep learning/medium_pickle/calculus__differentiate_medium.txt', '/content/drive/MyDrive/Deep learning/medium_pickle/probability__swr_p_level_set_medium.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path for hard train data:"
      ],
      "metadata": {
        "id": "0K8p7SMEApjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hard_path= os.path.join(save_path,\"hard_pickle\")\n",
        "hard_texts_path=[str(path) for path in Path(hard_path).glob(\"*.txt\")]\n",
        "print(hard_texts_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7pos2G7eMsR",
        "outputId": "a9805abb-c8c4-4a4f-9a71-925dcebec617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Deep learning/hard_pickle/algebra__linear_1d_hard.txt', '/content/drive/MyDrive/Deep learning/hard_pickle/calculus__differentiate_hard.txt', '/content/drive/MyDrive/Deep learning/hard_pickle/probability__swr_p_level_set_hard.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path for interpolate data:"
      ],
      "metadata": {
        "id": "_cDGRuQdAxE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpolate_path= os.path.join(save_path,\"interpolate_pickle\")\n",
        "interpolate_texts_path=[str(path) for path in Path(interpolate_path).glob(\"*.txt\")]\n",
        "print(interpolate_texts_path)"
      ],
      "metadata": {
        "id": "Q2vkjK2BAuNg",
        "outputId": "0c1de2d1-c024-4477-ba99-abad9aa8364c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Deep learning/interpolate_pickle/algebra__linear_1d.txt', '/content/drive/MyDrive/Deep learning/interpolate_pickle/calculus__differentiate.txt', '/content/drive/MyDrive/Deep learning/interpolate_pickle/probability__swr_p_level_set.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vocabulary_from_directory(sentences_path):\n",
        "  vocabulary = {}\n",
        "  vocabulary['<sos>'] = 1\n",
        "  vocabulary['<eos>'] = 2\n",
        "  vocabulary['<pad>'] = 0\n",
        "  index = 3\n",
        "  conta = 0\n",
        "  for file in sentences_path:\n",
        "    with open(file, 'r') as file_in:\n",
        "      text = file_in.read()\n",
        "      sentences = text.split('\\n')\n",
        "      sentences_new = sentences[:-1] #remove last element because it's empty\n",
        "      print(\"num sentences\", len(sentences_new))\n",
        "      for s in sentences_new:\n",
        "        conta +=1\n",
        "        for t in s:\n",
        "         if t not in vocabulary:\n",
        "            vocabulary[t] = index\n",
        "            index += 1\n",
        "      file_in.close()\n",
        "  return vocabulary, conta"
      ],
      "metadata": {
        "id": "NenOz7Bnz1gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary, conta = create_vocabulary_from_directory(ft_texts_path)\n",
        "# print(conta)"
      ],
      "metadata": {
        "id": "gw7vYDuiy5hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #create the pickle\n",
        "# outfile = open(os.path.join(save_path,\"vocabs\"), 'wb')\n",
        "# pickle.dump(vocabulary, outfile)\n",
        "# outfile.close()"
      ],
      "metadata": {
        "id": "hozVF8z6KqDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoding_from_sentence(vocab, sentence):\n",
        "  enc= [1]\n",
        "  for token in sentence:\n",
        "    enc.append(vocab[token])\n",
        "  enc.append(2)\n",
        "  return enc"
      ],
      "metadata": {
        "id": "yE-32CsOX3en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pickles(vocabulary, sentences_paths, column_names=[\"Encoding\"], path_quest=\"/content/drive/MyDrive/Deep learning/questions\", path_answ=\"/content/drive/MyDrive/Deep learning/answers\"):\n",
        "  quest = []\n",
        "  answ = []\n",
        "  out_file_quest = open(path_quest, 'wb')\n",
        "  out_file_answ = open(path_answ, 'wb')\n",
        "  for file in sentences_paths:\n",
        "    with open(file, 'r') as file_in:\n",
        "      text = file_in.read()\n",
        "      sentences = text.split('\\n')\n",
        "      sentences = sentences[:-1]\n",
        "      print(\"num sentences\", len(sentences))\n",
        "      for i, sentence in enumerate(sentences):\n",
        "          enc = encoding_from_sentence(vocabulary, sentence)\n",
        "          if i % 2 == 0: #question\n",
        "            #quest.append({\"Sentence\": sentence, \"Encoding\": enc})\n",
        "            quest.append({\"Encoding\": enc})\n",
        "          elif i % 2 == 1: #answer\n",
        "            #answ.append({\"Sentence\": sentence, \"Encoding\": enc})\n",
        "            answ.append({\"Encoding\": enc})\n",
        "  pickle.dump(quest, out_file_quest)\n",
        "  pickle.dump(answ, out_file_answ)\n",
        "  out_file_quest.close()\n",
        "  out_file_answ.close()\n",
        "  return path_quest, path_answ"
      ],
      "metadata": {
        "id": "VJbw05t8Mjdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "C8mQUo-4MPvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unpickle the vocabulary\n",
        "infile = open(os.path.join(save_path,'vocabs'),'rb')\n",
        "vocab = pickle.load(infile)\n",
        "infile.close()"
      ],
      "metadata": {
        "id": "eJKBOht4EPHd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute if you want to train easy data:"
      ],
      "metadata": {
        "id": "rb7cgdXyA7eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unpickle the qestions\n",
        "with open(os.path.join(easy_path,\"questions\"),'rb') as infile:\n",
        "  quest = pickle.load(infile)\n",
        "print(len(quest))\n",
        "\n",
        "#unpickle the answers\n",
        "with open(os.path.join(easy_path,\"answers\"),'rb') as infile:\n",
        "  answ = pickle.load(infile)\n",
        "print(len(answ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoXn82htefTr",
        "outputId": "25394d07-31e0-4062-e161-88e0f6b1dea7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1999998\n",
            "1999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute if you want to train medium data:"
      ],
      "metadata": {
        "id": "RYcpWDaYA---"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unpickle the qestions\n",
        "with open(os.path.join(medium_path,\"questions\"),'rb') as infile:\n",
        "  quest = pickle.load(infile)\n",
        "print(len(quest))\n",
        "\n",
        "#unpickle the answers\n",
        "with open(os.path.join(medium_path,\"answers\"),'rb') as infile:\n",
        "  answ = pickle.load(infile)\n",
        "print(len(answ))"
      ],
      "metadata": {
        "id": "t8e47VRR05pB",
        "outputId": "9ad136f2-57d7-4c11-ecc8-cdd806022d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d1cb1ae34c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#unpickle the qestions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedium_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"questions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mquest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'medium_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute if you want to train hard data:"
      ],
      "metadata": {
        "id": "tFdhkvjIBGdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unpickle the qestions\n",
        "with open(os.path.join(hard_path,\"questions\"),'rb') as infile:\n",
        "  quest = pickle.load(infile)\n",
        "print(len(quest))\n",
        "\n",
        "#unpickle the answers\n",
        "with open(os.path.join(hard_path,\"answers\"),'rb') as infile:\n",
        "  answ = pickle.load(infile)\n",
        "print(len(answ))"
      ],
      "metadata": {
        "id": "VugmdRjuBJSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute to load test:"
      ],
      "metadata": {
        "id": "9JUXVoRZmh6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unpickle the qestions\n",
        "with open(os.path.join(interpolate_path,\"questions\"),'rb') as infile:\n",
        "  test_quest = pickle.load(infile)\n",
        "print(len(test_quest))\n",
        "\n",
        "#unpickle the answers\n",
        "with open(os.path.join(interpolate_path,\"answers\"),'rb') as infile:\n",
        "  test_answ = pickle.load(infile)\n",
        "print(len(test_answ))"
      ],
      "metadata": {
        "id": "F4EQ4DGVBZac",
        "outputId": "a2bd2e08-d8ac-48c4-eef6-1ba728fa2a81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30000\n",
            "30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MathematicsDataset(Dataset):\n",
        "  def __init__(self, quest, answ, vocab , max_len_quest=160, max_len_answ=30):\n",
        "    self.quest = quest\n",
        "    self.answ = answ\n",
        "    self.vocab = vocab\n",
        "    self.max_len_quest = max_len_quest\n",
        "    self.max_len_answ = max_len_answ\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.quest)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    assert(idx  < len(self.quest)) #indices should start from 0 to len - 1 (there are 5999994 elements)\n",
        "    question = self.quest[idx][\"Encoding\"]\n",
        "    encoding1 = torch.from_numpy(create_padding(question, self.vocab, self.max_len_quest))\n",
        "    encoding1 = encoding1.type(torch.int64)\n",
        "    #self.sample[\"Question\"] = encoding\n",
        "      \n",
        "    answer = self.answ[idx][\"Encoding\"]\n",
        "    encoding2 = torch.from_numpy(create_padding(answer, self.vocab, self.max_len_answ))\n",
        "    encoding2 = encoding2.type(torch.int64)\n",
        "    #self.sample[\"Answer\"] = encoding\n",
        "      \n",
        "    return encoding1, encoding2 "
      ],
      "metadata": {
        "id": "bCskAS9LMNTT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlMathematicsDataset(pl.LightningDataModule):\n",
        "    def __init__(self, train_quest, train_answ, vocab , test_quest, test_answ, max_len_quest=160, max_len_answ=30, batch_size=128):\n",
        "        super().__init__()\n",
        "        self.train_quest = train_quest\n",
        "        self.train_answ = train_answ\n",
        "        self.test_quest = test_quest\n",
        "        self.test_answ = test_answ\n",
        "        self.vocab = vocab\n",
        "        self.max_len_quest = max_len_quest\n",
        "        self.max_len_answ = max_len_answ\n",
        "        self.batch_size = batch_size\n",
        "        self.dataset = MathematicsDataset(self.train_quest, self.train_answ, self.vocab)\n",
        "\n",
        "    # def prepare_data(self):\n",
        "        # tok, load, ecc...\n",
        "        # MNIST(self.data_dir, train=True, download=True)\n",
        "        # MNIST(self.data_dir, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "\n",
        "        # Assign train/val datasets for use in dataloaders\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            self.train_ds = MathematicsDataset(self.train_quest, self.train_answ, self.vocab)\n",
        "\n",
        "        # Assign test dataset for use in dataloader(s)\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.test_ds = MathematicsDataset(self.test_quest, self.test_answ, self.vocab)\n",
        "\n",
        "        if stage == \"predict\" or stage is None:\n",
        "            self.predict_ds = MathematicsDataset(self.test_quest, self.test_answ, self.vocab)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle = True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_ds, batch_size=self.batch_size)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(self.predict_ds, batch_size=self.batch_size)"
      ],
      "metadata": {
        "id": "dXLqCNPH1ZNQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dataset\n",
        "dataset = PlMathematicsDataset(quest, answ, vocab, test_quest, test_answ)"
      ],
      "metadata": {
        "id": "sAQcoCkOo44i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Create dataloader\n",
        "# train_loader = DataLoader(dataset, 32, shuffle=True)\n",
        "# print(len(train_loader))"
      ],
      "metadata": {
        "id": "03Zzt0OmDgbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"data\", next(iter(train_loader)))\n",
        "# print(\"questions_shape \", next(iter(train_loader))[0].shape)\n",
        "\n",
        "# print(\"answers_shape \", next(iter(train_loader))[1].shape)"
      ],
      "metadata": {
        "id": "uWqFcYLND4ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "Kf5YD-k_z5H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingLayer(nn.Module):\n",
        "  def __init__(self,vocabulary_size,embedding_dim):\n",
        "    super().__init__()\n",
        "    self.E = nn.Embedding(vocabulary_size,embedding_dim)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.E(x)"
      ],
      "metadata": {
        "id": "C4i4vs8nLKNz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def position_embedding(batch_size,seq_length,emb_dim,pad_mask):\n",
        "  res = torch.zeros((batch_size,seq_length,emb_dim),dtype=torch.float32)\n",
        "  for pos in range(seq_length):\n",
        "    for i in range(emb_dim):\n",
        "      if i%2 == 0:\n",
        "        res[:,pos,i] = math.sin(pos/10000**(2*i/emb_dim))\n",
        "      else:\n",
        "        res[:,pos,i] = math.cos(pos/10000**(2*i/emb_dim))\n",
        "  res[pad_mask[:,0,:]] = 0\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  return res.to(device)"
      ],
      "metadata": {
        "id": "B8E2HleXTgFz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TPSelfAttention(nn.Module):\n",
        "  def __init__(self,dz,dk):\n",
        "    super().__init__()\n",
        "    self.dk = dk\n",
        "    self.Wq = nn.Linear(dz,dk)\n",
        "    self.Wk = nn.Linear(dz,dk)\n",
        "    self.Wv = nn.Linear(dz,dk)\n",
        "    self.Wr = nn.Linear(dz,dk)\n",
        "    self.Wo = nn.Linear(dk,dz)\n",
        "    self.softmax = nn.Softmax(dim=2)\n",
        "  \n",
        "  def forward(self,x,padding_mask,enc=None,mask=False,other_mask=None):\n",
        "    q = self.Wq(x)\n",
        "    r = self.Wr(x)\n",
        "    if enc == None:\n",
        "      k = self.Wk(x)\n",
        "      v = self.Wv(x)\n",
        "    else:\n",
        "      k = self.Wk(enc)\n",
        "      v = self.Wv(enc)\n",
        "    sc = torch.matmul(q,k.permute(0,2,1)) / math.sqrt(self.dk)\n",
        "\n",
        "    if other_mask == None:\n",
        "      sc[padding_mask] = float('-inf')\n",
        "    else:\n",
        "      qmod = q.clone()\n",
        "      kmod = k.clone()\n",
        "      qmod[padding_mask[:,0,:]] = 0\n",
        "      kmod[other_mask[:,0,:]] = 0\n",
        "      sc = torch.matmul(qmod,kmod.permute(0,2,1)) / math.sqrt(self.dk)\n",
        "      sc[sc == 0] = float('-inf')\n",
        "\n",
        "    if mask==True:\n",
        "      for i in range(sc.shape[1]):\n",
        "        sc[:,i,i+1:] = float('-inf')\n",
        "    score = torch.matmul(torch.nan_to_num(self.softmax(sc)),v)\n",
        "    return self.Wo(r * score)"
      ],
      "metadata": {
        "id": "v9OoIF1MgYIw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TPMultiHeadAttention(nn.Module):\n",
        "  def __init__(self,dmodel,nhead,dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.nhead = nhead\n",
        "    self.att_layers = nn.ModuleList([TPSelfAttention(dmodel,dmodel // nhead) for i in range(nhead)])\n",
        "    self.drop = nn.Dropout(p=dropout)\n",
        "  \n",
        "  def forward(self,x,padding_mask,enc=None,mask=False,other_mask=None):\n",
        "    y = self.att_layers[0](x,padding_mask,enc=enc,mask=mask,other_mask=other_mask)\n",
        "    for i in range(1,self.nhead):\n",
        "      y += self.att_layers[i](x,padding_mask,enc=enc,mask=mask,other_mask=other_mask)\n",
        "    y = self.drop(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "wJS-HOR2mYjA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FFN(nn.Module):\n",
        "  def __init__(self,dmodel,df,dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.W1 = nn.Linear(dmodel,df)\n",
        "    self.W2 = nn.Linear(df,dmodel)\n",
        "    self.drop = nn.Dropout(p=dropout)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.W1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.W2(x)\n",
        "    x = self.drop(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Q3a-LqjhyGER"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,dmodel,df,nhead):\n",
        "    super().__init__()\n",
        "    self.norm = LayerNorm(dmodel)\n",
        "    self.mha = TPMultiHeadAttention(dmodel,nhead)\n",
        "    self.norm1 = LayerNorm(dmodel)\n",
        "    self.ffn = FFN(dmodel,df)\n",
        "    self.norm2 = LayerNorm(dmodel)\n",
        "  \n",
        "  def forward(self,x,padding_mask):\n",
        "    x = self.norm(x)\n",
        "    z = self.mha(x,padding_mask)\n",
        "    z = self.norm1(x+z)\n",
        "    y = self.ffn(z)\n",
        "    return self.norm2(z+y)"
      ],
      "metadata": {
        "id": "mIPuC2RAypA5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,dmodel,df,nhead):\n",
        "    super().__init__()\n",
        "    self.norm = LayerNorm(dmodel)\n",
        "    self.masked_mha = TPMultiHeadAttention(dmodel,nhead)\n",
        "    self.norm1 = LayerNorm(dmodel)\n",
        "    self.enc_dec_attention = TPMultiHeadAttention(dmodel,nhead)\n",
        "    self.norm2 = LayerNorm(dmodel)\n",
        "    self.ffn = FFN(dmodel,df)\n",
        "    self.norm3 = LayerNorm(dmodel)\n",
        "  \n",
        "  def forward(self,x,enc,padding_mask,other_mask):\n",
        "    x = self.norm(x)\n",
        "    z1= self.masked_mha(x,padding_mask,mask=True)\n",
        "    z1 = self.norm1(x+z1)\n",
        "    z2= self.enc_dec_attention(z1,padding_mask,enc=enc,mask=False,other_mask=other_mask)\n",
        "    z2 = self.norm2(z1+z2)\n",
        "    y = self.ffn(z2)\n",
        "    return self.norm3(z2+y)"
      ],
      "metadata": {
        "id": "DLqzXKv6kRua"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TPTransformer(pl.LightningModule):\n",
        "    def __init__(self,voc_size,dmodel,df,nhead,nlayers,dropout=0.1):\n",
        "      super().__init__()\n",
        "      self.save_hyperparameters()\n",
        "      self.nlayers = nlayers\n",
        "      self.embedding = EmbeddingLayer(voc_size,dmodel)\n",
        "      self.encoders = nn.ModuleList([Encoder(dmodel,df,nhead) for i in range(nlayers)])\n",
        "      self.decoders = nn.ModuleList([Decoder(dmodel,df,nhead) for i in range(nlayers)])\n",
        "      self.drop1 = nn.Dropout(p=dropout)\n",
        "      self.drop2 = nn.Dropout(p=dropout)\n",
        "      self.dmodel = dmodel\n",
        "      self.metric = nn.CrossEntropyLoss()\n",
        "      self.test_acc = torchmetrics.Accuracy(task='multiclass', num_classes = voc_size)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step defines the train loop.\n",
        "        input, teacher = batch\n",
        "        in_pad_mask = get_padding_mask(input)\n",
        "        out_pad_mask = get_padding_mask(teacher)\n",
        "        x,output = tran(input,teacher,in_pad_mask,out_pad_mask)\n",
        "        pred = output[:,:-1,:].reshape(output.shape[0]*(output.shape[1] - 1),output.shape[2])\n",
        "        target = teacher[:,1:].reshape(teacher.shape[0]*(teacher.shape[1] - 1))\n",
        "        loss = self.metric(pred,target)\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(tran.parameters(),lr=1e-04, betas=(0.9, 0.995), eps=1e-09)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        enc = True\n",
        "        trg = y.clone()\n",
        "        input_pad_mask = get_padding_mask(x)\n",
        "        for i in range(1,y.shape[1]):\n",
        "          output_pad_mask = get_padding_mask(trg[:,:i])\n",
        "          x,output = tran(x,trg[:,:i],input_pad_mask,output_pad_mask,encoding = enc)\n",
        "          trg[:,i] = output.argmax(-1)[:,-1]\n",
        "          enc = False\n",
        "        target_pad_mask = get_padding_mask(y[:,1:])\n",
        "        acc = self.test_acc(output.argmax(-1)[target_pad_mask[:,0,:]], y[:,1:][target_pad_mask[:,0,:]])\n",
        "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return acc\n",
        "\n",
        "    def forward(self,x,z,in_padding_mask,out_padding_mask,encoding=True):\n",
        "      if encoding:\n",
        "        emb = self.embedding(x)\n",
        "        t = position_embedding(x.shape[0],x.shape[1],self.dmodel,in_padding_mask)\n",
        "        x = emb + t\n",
        "        x = self.drop1(x)\n",
        "        for i in range(self.nlayers):\n",
        "          x = self.encoders[i](x,in_padding_mask)\n",
        "\n",
        "      emb = self.embedding(z)\n",
        "      t = position_embedding(z.shape[0],z.shape[1],self.dmodel,out_padding_mask)\n",
        "      z = emb + t\n",
        "      z = self.drop2(z)\n",
        "      for i in range(self.nlayers):\n",
        "        z = self.decoders[i](z,x,out_padding_mask,in_padding_mask)\n",
        "      \n",
        "      z = z @ self.embedding.E.weight.T\n",
        "      z[out_padding_mask[:,0,:]] = 0\n",
        "\n",
        "      return x,z\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        enc = True\n",
        "        trg = y.clone()\n",
        "        input_pad_mask = get_padding_mask(x)\n",
        "        for i in range(1,y.shape[1]):\n",
        "          output_pad_mask = get_padding_mask(trg[:,:i])\n",
        "          x,output = tran(x,trg[:,:i],input_pad_mask,output_pad_mask,encoding = enc)\n",
        "          trg[:,i] = output.argmax(-1)[:,-1]\n",
        "          enc = False\n",
        "        return output.argmax(-1)"
      ],
      "metadata": {
        "id": "lQDvj4BD7TPX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dmodel = 512\n",
        "dk,dv = 64,64\n",
        "nhead = 8\n",
        "df = 512\n",
        "nlayers = 6\n",
        "vocabulary_size = len(vocab)\n",
        "enable_checkpointing = True\n",
        "resume_training = False\n",
        "load_model = False\n",
        "load_model_dir = \"/content/drive/MyDrive/Deep learning/model_checkpoints/TPTransformer/last.ckpt\" #change path to load a different checkpoint"
      ],
      "metadata": {
        "id": "K_rQ4Hrr9m9I"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tran = TPTransformer(vocabulary_size,dmodel,df,nhead,nlayers)\n",
        "if load_model == True:\n",
        "  tran = TPTransformer.load_from_checkpoint(load_model_dir)"
      ],
      "metadata": {
        "id": "rcDDXSJ38CgD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(dirpath=\"/content/drive/MyDrive/Deep learning/model_checkpoints/TPTransformer\", save_last =True, save_on_train_epoch_end = True)\n",
        "# define the logger object \n",
        "logger = TensorBoardLogger(\"tb_logs\", name=\"TPTransformer\",log_graph=True )\n",
        "\n",
        "#build the correct callbacks\n",
        "callbacks = [TQDMProgressBar(refresh_rate=20)]\n",
        "ckpt_path = load_model_dir\n",
        "\n",
        "#handle checkpointing\n",
        "if resume_training == False:\n",
        "  ckpt_path = None\n",
        "if enable_checkpointing == True:\n",
        "  callbacks = [checkpoint_callback, TQDMProgressBar(refresh_rate=20)]\n",
        "  \n",
        "#passing it to the trainer\n",
        "gpu = 0\n",
        "if torch.cuda.is_available() : \n",
        "  gpu = 1\n",
        "trainer = pl.Trainer(enable_checkpointing=enable_checkpointing ,gpus=gpu, max_epochs=3, logger=logger, callbacks=callbacks)\n",
        "trainer.fit(ckpt_path=ckpt_path, model=tran, datamodule=dataset)\n",
        "print(checkpoint_callback.best_model_path)"
      ],
      "metadata": {
        "id": "muqI9nijLoyi",
        "outputId": "eab87cc1-fc58-4372-d2c5-fcb82bacaecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572,
          "referenced_widgets": [
            "5d9c608b1d90413887825d871296cdd2",
            "a4c4ffed5ac94647957b460ad4eb08d8",
            "790be6408edb4b9c9ffea8d11c66d1e5",
            "ed066fbfebd94bfeb764fb6ce2bb78bb",
            "3d5e01f3a2ad4c79828df95b67aebd43",
            "6779fcbea64b47fd83671cb969a15fed",
            "3b058c3412694c23b94c9de351593c34",
            "7de1a75bab3d419c91544d2b8a23d2cc",
            "80b58710ce254035bfa611290d9bfe79",
            "cf9bd7ad2e5f4051ab7e8cf4ab59c879",
            "910e60784f7a4ef1a396c3fc8f7d2e7c"
          ]
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
            "  rank_zero_deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name      | Type               | Params\n",
            "-------------------------------------------------\n",
            "0 | embedding | EmbeddingLayer     | 29.7 K\n",
            "1 | encoders  | ModuleList         | 11.1 M\n",
            "2 | decoders  | ModuleList         | 19.0 M\n",
            "3 | drop1     | Dropout            | 0     \n",
            "4 | drop2     | Dropout            | 0     \n",
            "5 | metric    | CrossEntropyLoss   | 0     \n",
            "6 | test_acc  | MulticlassAccuracy | 0     \n",
            "-------------------------------------------------\n",
            "30.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "30.1 M    Total params\n",
            "120.320   Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/loggers/tensorboard.py:188: UserWarning: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1600: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d9c608b1d90413887825d871296cdd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1lKplZjRr839VnzCbCDMjd--WHVhTwnbR/Deep learning/model_checkpoints/TPTransformer/epoch=2-step=12.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute if you want interpolate data:"
      ],
      "metadata": {
        "id": "MUQgviypBUeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(tran,datamodule=dataset)"
      ],
      "metadata": {
        "id": "nxsrenIn-Lri",
        "outputId": "391005c3-0985-48c7-f1da-2ea6be930028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "135a2c3cfd2e433f9db5cc9fe0775cac",
            "a4f1ebe85e5d438fbe8a057b11542b7d",
            "0f6e1773e3384e85a232ed0b2acbeeae",
            "b69c69f55ed2412b986c38a5435fa3a2",
            "3f0b86d34b6448afaaaeb1a66a131e22",
            "ad0447576df8476f961aaa2101fb70b5",
            "b996c36a16d7461996eebeee32838f25",
            "cd5289872ded4076858e775b83bf054d",
            "dbbe334888d24fcbad00a1fd59e9a88f",
            "76fdd681bb95440b968d097435e388c9",
            "d87aefefc0e64fad914e8f26673e9c3f"
          ]
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "135a2c3cfd2e433f9db5cc9fe0775cac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     test_acc_epoch                0.875\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_acc_epoch': 0.875}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}